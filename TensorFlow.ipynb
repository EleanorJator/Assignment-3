{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 1:Looking back on scratch\n",
    "To implment for deep learing;\n",
    "\n",
    "I had to initialize weights and baises\n",
    "I needed an epoch loop to train over data multiple times \n",
    "I had to  initialize the nodes of each hidden layer of the network\n",
    "I performed forward propagation for each layer\n",
    "I needed to implement an activation function and applied it on the output of each layer\n",
    "I had to implement a loss function\n",
    "I had to implement back propagaiton method for the network\n",
    "I had to train the model using a fit method\n",
    "I had to implement an optimizer to update the values of weights and baises\n",
    "I also had to implement a predict method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 2:Considering  the correspondence between scratch and TensorFlow\n",
    " \n",
    "The sample code begins by performing feature selection and data processing on the iris dataset, followed by the definition of the mini batch class. Further down, the paramters for the layers in the class were initilized and assigned values. The exmaple_net function defines the forward propagation operation for the network. Loss_op, train_op, optimizer, and accuracy are used to calculate the loss, forward, backward propagation, and accuracy of the model respectively.\n",
    "The sample code is a deep learning logistic regression model implemented using tensor flow version 1. The model is trained to learn to distinguish between species of flowers, specifically iris flowers of the versicolor and virginica class.\n",
    "  \n",
    "  TensorFlow version one by default uses graph computation, therefore a session has to be created for the training of the model. This session was created using the tf.session method. Within this session, the model is trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "Iterator to get a mini-batch\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : The following forms of ndarray, shape (n_samples, n_features)\n",
    "      Training data\n",
    "    y : The following form of ndarray, shape (n_samples, 1)\n",
    "      Correct answer value\n",
    "    batch_size : int\n",
    "      Batch size\n",
    "    seed : int\n",
    "      NumPy random seed\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int_)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self._X[p0:p1], self._y[p0:p1]\n",
    "\n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0:p1], self._y[p0:p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "features = iris[\"data\"]\n",
    "target = iris[\"target\"]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=0.2)\n",
    "\n",
    "x_train, y_train, x_test, y_test = x_train.astype(np.float32), y_train.astype(np.float32), x_test.astype(np.float32), y_test.astype(np.float32)\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "onv = OneHotEncoder(sparse_output=False)\n",
    "y_train = onv.fit_transform(y_train)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 3:Creating a model of Iris using all three types of objective variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class Layer(tf.Module):\n",
    "    def __init__(self, n_input, n_output, activation=None, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.weight = tf.Variable(tf.random.normal([n_input, n_output]))\n",
    "        self.bais = tf.Variable(tf.random.normal([n_output]))\n",
    "        self.activation = activation\n",
    "\n",
    "    def __call__(self, x):\n",
    "        y = tf.add(tf.matmul(x, self.weight), self.bais)\n",
    "        if self.activation == None:\n",
    "            return y\n",
    "        return self.activation(y)\n",
    "\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, n_input = 4, n_classes=3,  lr=0.01, epoch=100, batch_size = 20):\n",
    "        self.lr = lr\n",
    "        self.epoch = epoch\n",
    "        self.batch = batch_size\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=self.lr)\n",
    "        self.inputlayer = Layer(n_input, 100, tf.nn.relu, \"InputLayer\")\n",
    "        self.hidden1 = Layer(100, 50, tf.nn.relu, \"hidden1\")\n",
    "        self.output = Layer(50,n_classes , name=\"outputLayer\")\n",
    "\n",
    "    #@tf.function\n",
    "    def forward(self, x):\n",
    "        logit = self.inputlayer(x)\n",
    "        logit = self.hidden1(logit)\n",
    "        logit = self.output(logit)\n",
    "\n",
    "        return logit\n",
    "\n",
    "    def fit(self, x_train, y_train, x_val=None, y_val=None):\n",
    "        if x_val is None:\n",
    "            x_val = x_train\n",
    "            y_val = y_train\n",
    "        for i in range(self.epoch):\n",
    "            total_loss = 0\n",
    "            for mini_x, mini_y in GetMiniBatch(x_train, y_train, self.batch):\n",
    "                with tf.GradientTape() as tape:\n",
    "                    logit = self.forward(mini_x)\n",
    "                    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(mini_y, logit))\n",
    "\n",
    "                gradient = tape.gradient(loss, tape.watched_variables())\n",
    "                self.optimizer.apply_gradients(zip(gradient, tape.watched_variables()))\n",
    "                total_loss+= loss\n",
    "            total_loss/=self.batch\n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "                logit = self.forward(x_val)\n",
    "                loss_val = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y_val, logit))\n",
    "            accuracy = accuracy_score(np.argmax(y_train, 1), self.predict(x_train))\n",
    "            gradient = tape.gradient(loss_val, tape.watched_variables())\n",
    "            self.optimizer.apply_gradients(zip(gradient, tape.watched_variables()))\n",
    "\n",
    "            print(f\"Num epoch: {i} loss: {total_loss}: loss_val: {loss_val} accuracy: {accuracy}\")\n",
    "        return self\n",
    "\n",
    "    def predict(self, x):\n",
    "        y = tf.nn.softmax(self.forward(x)).numpy()\n",
    "\n",
    "        return np.argmax(y, 1)\n",
    "\n",
    "\n",
    "def accuracy_score(y_true, pred):\n",
    "    correct = np.sum(np.round(y_true) == np.round(pred))\n",
    "    total = y_true.shape[0]\n",
    "    return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num epoch: 0 loss: 22.22698974609375: loss_val: 22.45050811767578 accuracy: 0.59375\n",
      "Num epoch: 1 loss: 9.427495956420898: loss_val: 35.029335021972656 accuracy: 0.65625\n",
      "Num epoch: 2 loss: 2.692002534866333: loss_val: 15.996060371398926 accuracy: 0.6979166666666666\n",
      "Num epoch: 3 loss: 1.9227867126464844: loss_val: 3.5300543308258057 accuracy: 0.8125\n",
      "Num epoch: 4 loss: 0.9897440075874329: loss_val: 0.0006869095377624035 accuracy: 0.96875\n",
      "Num epoch: 5 loss: 0.4860326647758484: loss_val: 2.3807318210601807 accuracy: 0.90625\n",
      "Num epoch: 6 loss: 0.21040944755077362: loss_val: 0.022190146148204803 accuracy: 0.9583333333333334\n",
      "Num epoch: 7 loss: 0.24463710188865662: loss_val: 0.002115904586389661 accuracy: 0.96875\n",
      "Num epoch: 8 loss: 0.1550915241241455: loss_val: 0.4997902810573578 accuracy: 0.9375\n",
      "Num epoch: 9 loss: 0.174977108836174: loss_val: 2.155679430870805e-05 accuracy: 0.9583333333333334\n",
      "Num epoch: 10 loss: 0.07464854419231415: loss_val: 0.6683877110481262 accuracy: 0.9375\n",
      "Num epoch: 11 loss: 0.08736202865839005: loss_val: 0.0016292253276333213 accuracy: 0.9791666666666666\n",
      "Num epoch: 12 loss: 0.06639306992292404: loss_val: 0.37384167313575745 accuracy: 0.9479166666666666\n",
      "Num epoch: 13 loss: 0.07620689272880554: loss_val: 0.005437670275568962 accuracy: 0.9791666666666666\n",
      "Num epoch: 14 loss: 0.06709087640047073: loss_val: 0.0025119527708739042 accuracy: 0.9791666666666666\n",
      "Num epoch: 15 loss: 0.05421656370162964: loss_val: 0.1281701773405075 accuracy: 0.9583333333333334\n",
      "Num epoch: 16 loss: 0.06088735908269882: loss_val: 0.048163801431655884 accuracy: 0.9583333333333334\n",
      "Num epoch: 17 loss: 0.07521224021911621: loss_val: 1.9218774468754418e-05 accuracy: 0.96875\n",
      "Num epoch: 18 loss: 0.05706552416086197: loss_val: 0.5472585558891296 accuracy: 0.9375\n",
      "Num epoch: 19 loss: 0.07885892689228058: loss_val: 1.3170841157261748e-05 accuracy: 0.96875\n",
      "Num epoch: 20 loss: 0.06470859795808792: loss_val: 0.49351072311401367 accuracy: 0.9375\n",
      "Num epoch: 21 loss: 0.07816100865602493: loss_val: 1.960059853445273e-05 accuracy: 0.96875\n",
      "Num epoch: 22 loss: 0.063975490629673: loss_val: 0.4753495156764984 accuracy: 0.9375\n",
      "Num epoch: 23 loss: 0.07585620880126953: loss_val: 2.0151628632447682e-05 accuracy: 0.96875\n",
      "Num epoch: 24 loss: 0.05750175565481186: loss_val: 0.56633460521698 accuracy: 0.9375\n",
      "Num epoch: 25 loss: 0.07796573638916016: loss_val: 7.905028905952349e-05 accuracy: 0.96875\n",
      "Num epoch: 26 loss: 0.06456173956394196: loss_val: 0.4571492671966553 accuracy: 0.9375\n",
      "Num epoch: 27 loss: 0.079363152384758: loss_val: 0.0002740037743933499 accuracy: 0.96875\n",
      "Num epoch: 28 loss: 0.0755549892783165: loss_val: 0.4388073980808258 accuracy: 0.9375\n",
      "Num epoch: 29 loss: 0.11014582961797714: loss_val: 0.09757093340158463 accuracy: 0.9479166666666666\n",
      "Num epoch: 30 loss: 0.11654709279537201: loss_val: 0.10844216495752335 accuracy: 0.9479166666666666\n",
      "Num epoch: 31 loss: 0.13162215054035187: loss_val: 0.13221551477909088 accuracy: 0.9479166666666666\n",
      "Num epoch: 32 loss: 0.14087846875190735: loss_val: 0.030321450904011726 accuracy: 0.96875\n",
      "Num epoch: 33 loss: 0.15742357075214386: loss_val: 0.22188395261764526 accuracy: 0.9479166666666666\n",
      "Num epoch: 34 loss: 0.15871362388134003: loss_val: 0.08881727606058121 accuracy: 0.9479166666666666\n",
      "Num epoch: 35 loss: 0.14342106878757477: loss_val: 0.1290598213672638 accuracy: 0.9479166666666666\n",
      "Num epoch: 36 loss: 0.1462537795305252: loss_val: 0.03511946648359299 accuracy: 0.9791666666666666\n",
      "Num epoch: 37 loss: 0.129686176776886: loss_val: 0.0002820707450155169 accuracy: 0.96875\n",
      "Num epoch: 38 loss: 0.16884386539459229: loss_val: 0.0006208450649864972 accuracy: 0.9791666666666666\n",
      "Num epoch: 39 loss: 0.1580568552017212: loss_val: 0.056922975927591324 accuracy: 0.9479166666666666\n",
      "Num epoch: 40 loss: 0.1990395486354828: loss_val: 0.0015350704779848456 accuracy: 0.9791666666666666\n",
      "Num epoch: 41 loss: 0.17651058733463287: loss_val: 0.11550727486610413 accuracy: 0.9479166666666666\n",
      "Num epoch: 42 loss: 0.2606774568557739: loss_val: 0.03575615957379341 accuracy: 0.9791666666666666\n",
      "Num epoch: 43 loss: 0.12040424346923828: loss_val: 0.041142795234918594 accuracy: 0.9791666666666666\n",
      "Num epoch: 44 loss: 0.09107819199562073: loss_val: 0.3897865116596222 accuracy: 0.9583333333333334\n",
      "Num epoch: 45 loss: 0.06299126148223877: loss_val: 0.03209957480430603 accuracy: 0.9791666666666666\n",
      "Num epoch: 46 loss: 0.021540243178606033: loss_val: 0.6366832852363586 accuracy: 0.9479166666666666\n",
      "Num epoch: 47 loss: 0.06711769104003906: loss_val: 0.01008868683129549 accuracy: 0.9791666666666666\n",
      "Num epoch: 48 loss: 0.04290191829204559: loss_val: 0.05520966649055481 accuracy: 0.9791666666666666\n",
      "Num epoch: 49 loss: 0.023408155888319016: loss_val: 0.5752753019332886 accuracy: 0.9479166666666666\n",
      "Num epoch: 50 loss: 0.08814594894647598: loss_val: 3.223505927962833e-06 accuracy: 0.9791666666666666\n",
      "Num epoch: 51 loss: 0.021375805139541626: loss_val: 0.42927446961402893 accuracy: 0.9479166666666666\n",
      "Num epoch: 52 loss: 0.09458132833242416: loss_val: 7.354187255259603e-05 accuracy: 0.9791666666666666\n",
      "Num epoch: 53 loss: 0.06821364164352417: loss_val: 2.836103476511198e-06 accuracy: 0.9791666666666666\n",
      "Num epoch: 54 loss: 0.05880005285143852: loss_val: 0.44671010971069336 accuracy: 0.9479166666666666\n",
      "Num epoch: 55 loss: 0.07187287509441376: loss_val: 0.002124293940141797 accuracy: 0.9791666666666666\n",
      "Num epoch: 56 loss: 0.01088324747979641: loss_val: 0.38735613226890564 accuracy: 0.9479166666666666\n",
      "Num epoch: 57 loss: 0.03846827149391174: loss_val: 0.30866628885269165 accuracy: 0.9479166666666666\n",
      "Num epoch: 58 loss: 0.06120450422167778: loss_val: 0.0024163604248315096 accuracy: 0.9791666666666666\n",
      "Num epoch: 59 loss: 0.0428936704993248: loss_val: 0.0009587525855749846 accuracy: 0.9791666666666666\n",
      "Num epoch: 60 loss: 0.010466903448104858: loss_val: 0.2360902577638626 accuracy: 0.9583333333333334\n",
      "Num epoch: 61 loss: 0.08480997383594513: loss_val: 0.11026100069284439 accuracy: 0.9895833333333334\n",
      "Num epoch: 62 loss: 0.034612663090229034: loss_val: 0.21116387844085693 accuracy: 0.9791666666666666\n",
      "Num epoch: 63 loss: 0.024319028481841087: loss_val: 0.35483431816101074 accuracy: 0.9479166666666666\n",
      "Num epoch: 64 loss: 0.0652773380279541: loss_val: 0.000153581248014234 accuracy: 0.9791666666666666\n",
      "Num epoch: 65 loss: 0.02774723246693611: loss_val: 0.05027170479297638 accuracy: 0.9895833333333334\n",
      "Num epoch: 66 loss: 0.010503903031349182: loss_val: 0.18101529777050018 accuracy: 0.9791666666666666\n",
      "Num epoch: 67 loss: 0.06934389472007751: loss_val: 0.105439692735672 accuracy: 0.9791666666666666\n",
      "Num epoch: 68 loss: 0.04437748342752457: loss_val: 0.019326580688357353 accuracy: 0.9895833333333334\n",
      "Num epoch: 69 loss: 0.02329782210290432: loss_val: 0.16887027025222778 accuracy: 0.9479166666666666\n",
      "Num epoch: 70 loss: 0.02443159744143486: loss_val: 0.23366403579711914 accuracy: 0.9479166666666666\n",
      "Num epoch: 71 loss: 0.05193197727203369: loss_val: 0.0007080459618009627 accuracy: 0.9791666666666666\n",
      "Num epoch: 72 loss: 0.0648529976606369: loss_val: 0.009254337288439274 accuracy: 0.96875\n",
      "Num epoch: 73 loss: 0.03883538022637367: loss_val: 0.3479588031768799 accuracy: 0.9479166666666666\n",
      "Num epoch: 74 loss: 0.04910511523485184: loss_val: 0.0026294058188796043 accuracy: 0.9791666666666666\n",
      "Num epoch: 75 loss: 0.05135652422904968: loss_val: 3.919662776752375e-05 accuracy: 0.9791666666666666\n",
      "Num epoch: 76 loss: 0.02208034321665764: loss_val: 0.18254058063030243 accuracy: 0.96875\n",
      "Num epoch: 77 loss: 0.05998123809695244: loss_val: 0.24345381557941437 accuracy: 0.9479166666666666\n",
      "Num epoch: 78 loss: 0.060552626848220825: loss_val: 7.946896403154824e-06 accuracy: 0.9791666666666666\n",
      "Num epoch: 79 loss: 0.004642060957849026: loss_val: 0.015131532214581966 accuracy: 0.9895833333333334\n",
      "Num epoch: 80 loss: 0.03339458256959915: loss_val: 0.22803331911563873 accuracy: 0.9479166666666666\n",
      "Num epoch: 81 loss: 0.05501663684844971: loss_val: 2.5722072678036056e-05 accuracy: 0.9791666666666666\n",
      "Num epoch: 82 loss: 0.028934914618730545: loss_val: 0.00011534529039636254 accuracy: 0.9791666666666666\n",
      "Num epoch: 83 loss: 0.009268185123801231: loss_val: 0.09700287133455276 accuracy: 0.96875\n",
      "Num epoch: 84 loss: 0.0051657287403941154: loss_val: 0.09843193739652634 accuracy: 0.96875\n",
      "Num epoch: 85 loss: 0.012113865464925766: loss_val: 0.1407446265220642 accuracy: 0.9479166666666666\n",
      "Num epoch: 86 loss: 0.009371417574584484: loss_val: 0.07398346811532974 accuracy: 0.96875\n",
      "Num epoch: 87 loss: 0.009571840986609459: loss_val: 0.01964854635298252 accuracy: 0.9791666666666666\n",
      "Num epoch: 88 loss: 0.009548239409923553: loss_val: 0.0069460198283195496 accuracy: 1.0\n",
      "Num epoch: 89 loss: 0.011147947050631046: loss_val: 0.047553446143865585 accuracy: 0.96875\n",
      "Num epoch: 90 loss: 0.011992460116744041: loss_val: 0.1659439355134964 accuracy: 0.9479166666666666\n",
      "Num epoch: 91 loss: 0.014277076348662376: loss_val: 0.06770438700914383 accuracy: 0.96875\n",
      "Num epoch: 92 loss: 0.02523268200457096: loss_val: 0.0004609863681253046 accuracy: 0.9895833333333334\n",
      "Num epoch: 93 loss: 0.05101894214749336: loss_val: 0.014822307042777538 accuracy: 0.96875\n",
      "Num epoch: 94 loss: 0.02743307687342167: loss_val: 0.0848202034831047 accuracy: 0.96875\n",
      "Num epoch: 95 loss: 0.08917608112096786: loss_val: 0.43337181210517883 accuracy: 0.9166666666666666\n",
      "Num epoch: 96 loss: 0.09733784198760986: loss_val: 0.19221270084381104 accuracy: 0.9583333333333334\n",
      "Num epoch: 97 loss: 0.023879384621977806: loss_val: 0.060625091195106506 accuracy: 0.9583333333333334\n",
      "Num epoch: 98 loss: 0.08626701682806015: loss_val: 0.22922737896442413 accuracy: 0.9479166666666666\n",
      "Num epoch: 99 loss: 0.12402079254388809: loss_val: 0.485850065946579 accuracy: 0.9479166666666666\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.LogisticRegression at 0x11ea43ec610>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(x_train, y_train, x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(x_test)\n",
    "\n",
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'True value')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(pred, y_test)\n",
    "plt.xlabel(\"prediction\")\n",
    "plt.ylabel(\"True value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 4:Creating a model of House Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_train = pd.read_csv(\"C:\\Users\\cbt04\\Dpro_Assignments-\\Dpro_Assignments-\\train.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
